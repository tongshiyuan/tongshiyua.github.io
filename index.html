<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Taro">
<meta property="og:url" content="http://tongshiyuan.github.io/index.html">
<meta property="og:site_name" content="Taro">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Taro">



  <link rel="alternate" href="/atom.xml" title="Taro" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://tongshiyuan.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Taro</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/tongshiyuan" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Taro</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/18/WGS分析笔记（5）- annotation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/18/WGS分析笔记（5）- annotation/" class="post-title-link" itemprop="url">WGS分析笔记（5）- annotation</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-18 12:52:03 / 修改时间：13:45:05" itemprop="dateCreated datePublished" datetime="2019-06-18T12:52:03+08:00">2019-06-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp; 在找到很多变异以后（本文具体指的是snv以及indel），我们需要做的就是进行注释了，这是因为无论WGS还是WES，都会call出大量的变异。即使是一个正常人，也会有百万数量级的变异（详见<a href="https://tongshiyuan.github.io/2019/06/18/WGS分析笔记%EF%BC%884%EF%BC%89-%20Call%20SNVs%20indels/">上一章</a>），而我们需要做的是把其中可能有害的变异找出来。因此对于这么多的变异，就需要通过注释信息来筛选了（不同于call snv/indel以后的筛选，那是依据变异本身的可信度进行筛选的）。<br><br>&emsp;&emsp; 对于不同的研究目的，目前用的注释软件还是不少的，有专门针对肿瘤数据的注释软件（如oncotator等），也有孟德尔遗传疾病测序数据常用的annovar、vep等。<br><br>&emsp;&emsp; 本文主要讲的是通过annovar，对vcf文件进行注释，个人觉得annovar特别好用简单，说明书也写得很好，即使是我这种看了英语头晕的人，也能看的比较明白。<br></p>
<p>&emsp;&emsp; 比较一下annovar和vep，annovar软件是需要先申请再下载的，对于研究机构是免费的，对商业机构是收费的，只要你拿学邮去申请，应该就没有问题。而vep是免费的，但是呢，安装起来超级麻烦，本文虽然不用vep，但会在后面附上我当初安装vep的笔记。<br></p>
<p>&emsp;&emsp;annovar很人性化的一点是，当你下载到软件以后，直接解压就能用了，不用安装。而你需要注释什么数据库，按照官网说明书的词条直接下载就行。<br><br>&emsp;&emsp;本文主要讲述我在做课题的时候是如何使用的，具体的细节可以参考<a href="http://annovar.openbioinformatics.org/en/latest/" target="_blank" rel="noopener">官网说明书</a>或者别的大神们的使用笔记。<br><br>&emsp;&emsp;首先是下载数据，annovar提供了大量的数据库，可以单独下载也可以批量下载，主要是来源于annovar自己网站以及ucsc的，你要是批量下载是完全没有必要的，因为一个数据库可能有很多的版本，也有很多数据库是你不需要的，还有一些数据库所占空间那是相当的大。举几个我常用的数据库为例（我只是举例一些，建议是看看说明书根据需要下载）。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#注释基因</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar refGene humandb/</span><br><span class="line">#注释人群频率</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar esp6500siv2_all humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar exac03 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar gnomad_genome humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar 1000g2015aug humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar popfreq_max_20150413 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar popfreq_all_20150413 humandb/</span><br><span class="line">#预测打分</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar mcap13 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar revel humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar gerp++gt2 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar cadd13 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar dbnsfp35a humandb/</span><br><span class="line"># dbsnp</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 snp151 humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar avsnp150 humandb/</span><br><span class="line"># 致病位点公共数据库</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 gwasCatalog humandb/</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 -webfrom annovar clinvar_20190305 humandb/</span><br><span class="line">#区域注释</span><br><span class="line">$ perl annotate_variation.pl -downdb -buildver hg19 cytoBand humandb/</span><br><span class="line"># 稍微注意一下 humandb/ 是当前目录下有这么一个文件夹，用来放数据库的，这个路径关系到你用的时候的路径，你放在哪，用的时候把路径改成哪就行</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;然后是输入格式的转换，对于注释所需的输入文件，只需要前五列按照<code>avinput</code>的要求就行了，格式如下。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#分别以tab分隔</span><br><span class="line">染色体位置	起始位点    终止位点    参考基因组碱基    突变碱基</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;在注释完以后是不会保留原有的五列以外的内容的，转换脚本如下：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ perl convert2annovar.pl -format vcf4old in.vcf &gt; out.avinput</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;上面这个脚本除了把<code>vcf</code>转换为<code>avinput</code>以外，还会把一些多等位位点转换为单等位位点来注释，而格式之所以选用<code>vcf4old</code>，是因为我的输入格式是家系merge的vcf，一个vcf文件里有一家人的信息，如果是单个样本的话，直接用<code>vcf4</code>就行了。<br><br>&emsp;&emsp;用这种方式得到的结果就像我说的，注释完以后就没有保留 genotype等信息，除了前五列就只剩注释信息了。当然，也可以不转换格式，直接用<code>vcf</code>作为输入格式了，那么注释结果以标签的方式插入<code>vcf</code>文件之中，但是这样的话，会导致输出结果异常的占空间，因为，每一个数据库的头文件会反复出现在每一行被注释的变异中。提供参考脚本如下：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输入是vcf文件，要加上参数-vcfinput</span><br><span class="line">$ perl table_annovar.pl in.vcf /path/humandb/ -buildver hg19 -out myanno -remove -protocol refGene,cytoBand,exac03,avsnp147,dbnsfp30a -operation g,r,f,f,f -nastring . -vcfinput</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;虽然提供了这种方法，但我却是不建议的，尤其是我以WGS的文件作为输入，会使输出文件占很大的空间，但我又想保留 genotype信息，因为后面我需要这个信息判断变异的显隐性，这对于筛选是很关键的，那怎么办呢？<br><br>&emsp;&emsp;我想到的办法就是，在转换格式的时候，添加参数<code>-includeinfo</code>和<code>-comment</code>，前者的作用保留了genotype信息，后者保留了vcf的头文件。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ perl convert2annovar.pl -format vcf4old in.vcf -outfile out.avinput -comment -includeinfo</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;转换完格式就是注释了，虽然annovar提供了多种注释方式，但是我们一般都是批量注释，即像上面那个注释的例子一样，下面来简单说一下怎么批量注释。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ table_annovar.pl out.avinput /your/path/of/humandb/ \</span><br><span class="line">	--buildver hg19 -out /your/path/of/outfile -remove \</span><br><span class="line">	-protocol refGene,cytoBand,EAS.sites.2015_08,ALL.sites.2015_08,kaviar_20150923,hrcr1,cg69,gnomad_genome,exac03,exac03nonpsych,esp6500siv2_all,cg46 \</span><br><span class="line">	-operation g,r,f,f,f,f,f,f,f,f,f,f \</span><br><span class="line">	-nastring . --thread 12</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;来详细说一下我这个脚本有什么需要注意的地方，而我又是怎么应用于实际课题中的。<br><br>&emsp;&emsp;首先是out.avinput，就是上面转换之后的输出文件；之后跟着的就是我们下载数据库的目录；我用的是hg19的参考基因组；<code>-out</code>是输出文件的路径和输出文件的前缀；<code>-remove</code>表示删除注释过程中的临时文件;<code>-protocol</code>表示注释使用的数据库，用逗号隔开；<code>-operation</code> 表示对应顺序的数据库的类型（g代表gene-based、r代表region-based、f代表filter-based，可对照说明书），用逗号隔开，与<code>-protocol</code>顺序一一对应；<code>-nastring</code> 表示用点号替代缺省的值。<br><br>&emsp;&emsp;annovar其实提供了好多个<code>gene-based</code>数据库下载，refGene是NCBI提供的，还有ensembl、UCSC提供的ensGene、knowGene，这三个数据库是有所差别的，至于怎么选择，建议就和使用的参考基因组来源一致即可，比如我用的是NCBI上下载的参考基因组，那么就用refGene。<br><br>&emsp;&emsp;<code>-csvout</code> 表示最后输出.csv文件，使用这个参数得到的是csv格式的文件，可以直接用excel打开，但是我没有使用，输出是tab分隔的txt文件，方便后续我写脚本处理。为什么“,”分隔的csv文件不适合处理呢？那是因为refgene的注释结果也是逗号分隔的，在分析的时候就会出现问题。<br><br>&emsp;&emsp;<code>--thread</code>是线程数，当然线程数越高注释速度越快。<br><br>&emsp;&emsp;到了这一步以后，其实结果还是前五列avinput的内容，后面是注释的内容，genotype的信息还是没有掉了，这个时候就加一步，来解决一下这个问题。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ grep -v &quot;##&quot; out.avinput | cut -f1-9 --complement &gt; gt.txt</span><br><span class="line">$ paste hg19_multianno.txt gt.txt &gt; merge.anno.txt</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;很简单的两行命令，第一行提取了avinput文件里的genotype信息，然后第二行merge这个信息到注释完的文件上。这样得到的结果呢，又有注释信息，又有genotype信息，就很方便进行trio分析。<br><br>&emsp;&emsp;到这里其实就差不多了，可以进行下一步的筛选了，但是实际情况中，我们用到的数据库可能不止annovar提供的这些。毕竟annovar提供的数据库都是公开的数据库，而且对于日新月异的预测数据库等，annovar作者也不能做到每一种都去收录，如果你有一些自己下载的数据库，你该怎么利用annovar去注释呢？<br><br>&emsp;&emsp;这一类的数据库很多，比如omim需要申请才能下载，HGMD专业版需要付费订阅，这些annovar都是没有提供的。但是这些数据库在孟德尔遗传疾病中是很具有参考价值的，由于这两个都不能直接下载获得，这里也不详述，以两个近期发表在Nature Genetic上的公开的预测数据库为例，简述一下简单的方法构建自己的数据库。<br><br>&emsp;&emsp;annovar注释变异有两种注释方式，一个是基于区域，一个是基于位点，<a href="https://www.nature.com/articles/s41588-018-0294-6" target="_blank" rel="noopener">CCRS</a>就是一个基于区域的有害性预测打分工具，其数据可在这里下载，分为<a href="https://s3.us-east-2.amazonaws.com/ccrs/ccrs/ccrs.autosomes.v2.20180420.bed.gz" target="_blank" rel="noopener">常染色体</a>和<a href="https://s3.us-east-2.amazonaws.com/ccrs/ccrs/ccrs.xchrom.v2.20180420.bed.gz" target="_blank" rel="noopener">X染色体</a>；<a href="https://www.nature.com/articles/s41588-019-0348-4" target="_blank" rel="noopener">S-CAP</a>就是一个基于位点的splicing 区域有害性预测工具，其数据可以在<a href="http://bejerano.stanford.edu/scap/" target="_blank" rel="noopener">这里</a>下载。<br></p>
<h5 id="CCRS"><a href="#CCRS" class="headerlink" title="CCRS"></a>CCRS</h5><p>&emsp;&emsp;由于是基于区域的，那么在<code>-operation</code>参数里面呢是<code>r</code>，然后呢从网上下载下来的是一个bed文件，截取前十行，长这样。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/1.png" alt="ccrs"></p>
<p>&emsp;&emsp;这些信息其实我们只需要ccr_pct这一列的打分，为了方便起见，完全可以只保留前四列的内容，不然注释完会把所有前三列以后的内容都加到注释结果文件里。<br><br>&emsp;&emsp;那么这么一个文件是不能直接拿来用的，第一步就是改名。下载过annovar提供的数据库后可以知道，annovar使用的数据库都有自己的命名方式，这里的话直接改成 <code>hg19_ccrs.txt</code>即可，<code>hg19</code>表示所使用的参考基因组版本，因为CCRS 的坐标是基于hg19的，所以这里是hg19，ccrs就是<code>-protocol</code>参数里的标识符了，然后以<code>.txt</code>作为后缀。<br><br>&emsp;&emsp;然后是修改格式，一开始我用的方法是参考annovar提供的<code>region-based</code>数据库的格式，然后修改CCRS的格式。后来我发现这是行不通的，因为现成的数据库格式差别有点大，那么就只能看源码了。但其实我是不会perl的，在师姐的帮助下，完美的解决了这个问题。<br><br>&emsp;&emsp;虽然我们是使用<code>table_annovar.pl</code>进行注释的，实际上对于<code>region-based</code>数据库的注释是调用<code>annotate_variation.pl</code>，所以需要修改<code>annotate_variation.pl</code>的源码。在2998行我们可以看到，其实对于不同<code>region-based</code>数据库，都是有预设的。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/2.png" alt="annotate_variation.pl"></p>
<p>&emsp;&emsp;所以根据CCRS的格式，我们可以在这里添加一个预设语句块。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/3.png" alt="ccrs预设"></p>
<p>&emsp;&emsp;当然也可以根据最后一个<code>else语句块</code>修改CCRS的格式<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/4.png" alt="else语句块"></p>
<p>&emsp;&emsp;从这个语句块可以看出来，只需要在CCRS原始文件前面添加一列内容，以<code>tab</code>隔开，就行，添加啥也都无所谓，这里就不赘述了。<br></p>
<h5 id="S-CAP"><a href="#S-CAP" class="headerlink" title="S-CAP"></a>S-CAP</h5><p>&emsp;&emsp;由于是基于位点的，那么在<code>-operation</code>参数里面呢是<code>f</code>，然后呢从网上下载下来的文件，一共有八个文件（不同区域不同标准，可以参考论文），任意选取一个截取前十行，长这样。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/5.png" alt="S-CAP"></p>
<p>&emsp;&emsp;这里我已经把名字修改了，如果大家有查看过<code>filter-based</code>数据库，大抵都是这个格式，染色染位置、起始位置、结束位置、参考碱基、突变碱基、要注释的内容（可以是多列），以<code>tab</code>隔开。这里可以发现，少了一列结束位置，那是因为论文只针对snp，所以不用start、end表示也可以，这里用一个简单的语句就可以解决这一点。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F &quot;\t&quot; &apos;&#123;print $1&quot;\t&quot;$2&quot;\t&quot;$2&quot;\t&quot;$3&quot;\t&quot;$4&quot;\t&quot;$5&#125;&apos; scap3cr.txt &gt; hg19_scap3cr.txt</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;但是注意，这样是不够的，如果你看了这个论文，你会发现，这是预测splicing区域有害性的打分，更重要的是，论文中对splicing区域的划分和annovar默认的aplicing区域是不一样的！！！<br><br>&emsp;&emsp;在annovar里头，splicing的区域是2bp，也就是图中的1和4.<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/6.png" alt="splicing"><br>&emsp;&emsp;但是论文中作者为了更好的预测有害性，用了整整100bp的长度（内含子外显子各50bp），所以仅仅用annovar默认的splicing区域大小就太浪费这个打分了，那怎么扩大这个范围呢？<br><br>&emsp;&emsp;其实如果仔细看annovar说明书我们会发现，在<code>annotate_variation.pl</code>的脚本中有一个参数<code>--splicing_threshold</code>，可以控制splicing的区域大小，默认是2，但是我们用的是<code>table_annovar.pl</code>的脚本进行注释，虽然是调用<code>annotate_variation.pl</code>，但是却没有了<code>--splicing_threshold</code>这个参数，看来又只能改源码了。<br><br>&emsp;&emsp;在<code>table_annovar.pl</code>第380行（不同版本可能不太一样），有这么一句话。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（5）- annotation/7.png" alt="--splicing_threshold"></p>
<p>&emsp;&emsp;里面在调用<code>annotate_variation.pl</code>的时候，直接给了<code>--splicing_threshold</code>这个参数，只要把后面的数字改成50就好了（原来是2）。至于怎么建立索引可以参考<a href="https://mp.weixin.qq.com/s/_h-EkT9YvffSOuViYT_gGQ" target="_blank" rel="noopener">这里</a>，是否建立索引会影响注释速度，但不会影响结果。<br><br>&emsp;&emsp;至此，这一部分内容就完了，我在实践中也就是这么使用的，具体的根据需要可以好好读一读annovar的官网说明。<br></p>
<hr>
<p>&emsp;&emsp;水平有限，要是存在什么错误请评论指出，可发送邮件至<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>！请大家多多批评指正，相互交流，共同成长，谢谢！！！</p>
<h3 id="附（vep安装笔记）"><a href="#附（vep安装笔记）" class="headerlink" title="附（vep安装笔记）"></a>附（vep安装笔记）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#由于我用的是ubuntu server 18.04，不同linux发行版本之间的安装可能存在差异</span><br><span class="line">	$ git clone https://github.com/Ensembl/ensembl-vep.git</span><br><span class="line">	$ cd ensembl-vep</span><br><span class="line">	$ perl -MCPAN -e shell</span><br><span class="line">	$ cpan&gt;install DBI</span><br><span class="line">	$ cpan&gt;install Bio::DB::HTS</span><br><span class="line">	$ cpan&gt;install LWP::Simple </span><br><span class="line">	$ cpan&gt;install LWP::Protocol::https</span><br><span class="line">	$ cpan&gt;install Archive::Extract</span><br><span class="line">	$ cpan&gt;install Archive::Tar</span><br><span class="line">	$ cpan&gt;install Archive::Zip</span><br><span class="line">	$ cpan&gt;install CGI</span><br><span class="line">	$ cpan&gt;install Time::HiRes</span><br><span class="line">	$ cpan&gt;install DBD::mysql</span><br><span class="line">	$ cpan&gt;q</span><br><span class="line">	$ sudo apt-get install libdbd-mysql-perl</span><br><span class="line">	$ perl INSTALL.pl</span><br><span class="line">	$ perl INSTALL.pl --AUTO af --SPECIES homo_sapiens --ASSEMBLY GRCh37 --DESTDIR /your/path/of/vepdatabase/ --CACHEDIR /your/path/of/vepdatabase/</span><br><span class="line">	$ perl convert_cache.pl --species homo_sapiens --version 94_GRCh37 --dir /your/path/of/vepdatabase/</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/18/WGS分析笔记（4）- Call SNVs indels/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/18/WGS分析笔记（4）- Call SNVs indels/" class="post-title-link" itemprop="url">WGS分析笔记（4）- Call SNVs/indels</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-18 12:51:38 / 修改时间：13:42:33" itemprop="dateCreated datePublished" datetime="2019-06-18T12:51:38+08:00">2019-06-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近一直忙期末汇报和脚本编写，没来的及接着往下写文章，年前把这一块写了，然后再往下的分析流程就比较特异性了，做一步写一步那种，相对于这种已经常规化的流程（除了一些细节上的差异，别的都是大同小异的了），再往下的可能就不是很常规的分析手段了，不同的实验室有不同的分析方法，希望能够有大佬提点意见，多多交流。<br></p>
<hr>
<h3 id="“突变”区别"><a href="#“突变”区别" class="headerlink" title="“突变”区别"></a>“突变”区别</h3><p>&emsp;&emsp;对于WGS的数据，在处理完bam文件以后，就是call variations了，之后所有的工作其实都是针对variations进行分析，那么说到变异呢，其实中文的“变异”在英文里对应多个单词，经常看到傻傻分不清，这里稍微区别一下。<br><br>&emsp;&emsp;<em>mutation：核苷酸序列的永久性改变（来源于ACMG），在人群中小于1%或5%（来源于北大生物信息学公开课）<br></em><br>&emsp;&emsp;<em>polymorphism：在人群中频率超过1%（来源于ACMG），或超过5%（来源于北大生物信息学公开课）<br></em><br>&emsp;&emsp;<em>variation/variant：以上两个的总和（来源于北大生物信息学公开课）</em><br></p>
<h3 id="变异类型"><a href="#变异类型" class="headerlink" title="变异类型"></a>变异类型</h3><p>&emsp;&emsp;我们一般所说的variations主要有四大类：SNV，INDEL，SV，CNV。(有些call变异软件也会支持MNV的calling，但是我们很少考虑这一类变异)<br><br>&emsp;&emsp;&emsp;&emsp;SNV即单核苷酸位点变异（single nucleotide variants）<br><br>&emsp;&emsp;&emsp;&emsp;INDEL即小片段插入缺失（insertion and deletion）<br><br>&emsp;&emsp;&emsp;&emsp;SV即结构变异（structural variation）<br><br>&emsp;&emsp;&emsp;&emsp;CNV即拷贝数变异（copy number variation）<br></p>
<h3 id="SNV与SNP"><a href="#SNV与SNP" class="headerlink" title="SNV与SNP"></a>SNV与SNP</h3><p>&emsp;&emsp;说到SNV，可能大家也经常看到SNP（single nucleotide polymorphism），同样是混淆使用，这俩其实还是有一些区别的，看到上面对变异的区分，其实也能看出这俩的区别来：<br><br>&emsp;&emsp;一般SNP是二态的，SNV没有这样的限制，如果在一个物种中该单碱基变异的频率达到一定水平（1%）就叫SNP，而频率未知（比如仅仅在一个个体中发现）就叫SNV，SNV包含SNP。<br></p>
<h3 id="变异简述"><a href="#变异简述" class="headerlink" title="变异简述"></a>变异简述</h3><p>&emsp;&emsp;人基因组通常有4.1 - 5.0M的变异，但是99.9%都是由SNV和short indel造成。<br><br>&emsp;&emsp;通常，一个人全基因组内会有约 3.6 - 4.4 M 个 SNVs，绝大数（大于 95%）的高频（群体中等位基因频率大于 5%）的 SNP 在 dbSNP中有记录，高频的SNP一般都不是致病的主要突变位点。<br><br>&emsp;&emsp;通常，一个人全基因组内会有约 600K 的 Indel（&lt;50bp的插入缺失为small indel）。<br><br>&emsp;&emsp;编码区或剪接位点处发生的插入缺失都可能会改变蛋白的翻译。<br></p>
<h4 id="SV"><a href="#SV" class="headerlink" title="SV"></a>SV</h4><p>&emsp;&emsp;结构变异指的是在基因组上一些大的结构性的变异，比如大片段丢失（deletion）、大片段插入（insertion）、大片段重复（duplication）、拷贝数变异（copy number variants）、倒位（inversion）、易位（translocation）。一般来说，结构变异涉及的序列长度在1kb到3Mb之间。结构变异普遍存在于人类基因组中，是个人差异和一些疾病易感性的来源。结构变异还可能导致融合基因的发生，一些癌症已经证实和结构变异导致的基因融合事件有关。<br></p>
<h4 id="CNV"><a href="#CNV" class="headerlink" title="CNV"></a>CNV</h4><p>&emsp;&emsp;拷贝数变异指的是基因组上大片段序列拷贝数的增加或者减少，可分为缺失（deletion）和重复(duplication)两种类型，是一种重要的分子机制。CNV能够导致孟德尔遗传病与罕见疾病, 同时与包括癌症在内的复杂疾病相关，因此对于染色体水平的缺失、扩增的研究已经成为疾病研究热点。<br></p>
<p>以上数据在不同的数据库或文献上可能有所差异，但相去不远，具体的变异分类以及分布就不详述，可参考一些文献，下面说说怎么进行其中的SNV和indel的检测。<br></p>
<hr>
<p>&emsp;&emsp;以下我将提供两种分析方式的脚本（<a href="https://github.com/google/deepvariant" target="_blank" rel="noopener">DeepVariant</a>以及<a href="http://www.htslib.org/doc/bcftools.html" target="_blank" rel="noopener">bcftools</a>）和流程，为啥没有GATK？因为我觉得黄老师的这篇<a href="https://www.jianshu.com/p/0b0c4ab4c38a" target="_blank" rel="noopener">GATK分析流程</a>写得已经很好了，大家可以参考一下。<br></p>
<h3 id="Bcftools"><a href="#Bcftools" class="headerlink" title="Bcftools"></a>Bcftools</h3><p>&emsp;&emsp;与旧版的samtools+bcftools不同，作者为了避免bcftools和samtools的版本不同导致的不兼容，新版的bcftools可以自己完成call snv/indel的工作。<br><br>&emsp;&emsp;使用bcftools进行变异检测，一般分为三部曲，分别为三个模块mpileup、call、filter，当然，我们一般也不会分三步进行操作，而是使用管道（pipeline）进行编写脚本，这样能减少产生一些不必要的过程文件，同时提高自动化和效率，下面是我的实际使用脚本。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ bcftools mpileup --threads 12 -q 20 -Q 20 -Ou -f /your/path/of/reference /your/bamfile/after/sorted.merged.markdup | bcftools call --threads 12 -vm -Ov | bcftools filter --threads 12 -s FILTER -g 10 -G 10 -i &quot;%QUAL&gt;20 &amp;&amp; DP&gt;6 &amp;&amp; MQ&gt;50 &amp;&amp; (DP4[2]+DP4[3])&gt;4&quot; &gt; raw.tmp.vcf</span><br><span class="line">## bcftools mpileup检测变异;</span><br><span class="line"># --threads线程数</span><br><span class="line"># -q表示reads比对质量选择，MAPQ，默认0;</span><br><span class="line"># -Q表示reads碱基对质量选择，默认13</span><br><span class="line"># -O表示输出格式,u表示未压缩bcf格式;</span><br><span class="line"># -f参考序列位置</span><br><span class="line">## bcftools call参数</span><br><span class="line"># --threads线程;</span><br><span class="line"># -v只输出变异位点;</span><br><span class="line"># m为克服-c调用模型中已知的局限性(与-c冲突)而设计的多等位和罕见变异调用的替代模型;</span><br><span class="line"># -O输出文件格式v未压缩vcf;</span><br><span class="line">## bcftools filter筛选变异;-i只保留后面条件的;-s对不符合的变异打上标签</span><br><span class="line">$ awk -F &quot;\t&quot; &apos;&#123;if($1~/#/)&#123;print&#125;else if($7~/PASS/)&#123;print&#125;&#125;&apos; raw.tmp.vcf &gt; var.flt.vcf</span><br><span class="line"># 将标为低质量的变异去掉</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;有几个点值得讨论一下，首先是mpileup的-q参数，这个和之前提到的samtools view的-q是一样的，前面的文章有大篇幅说过这个MAPQ的数值，20翻译过来的意思其实就是比对正确率99%。<br><br>&emsp;&emsp;filter中的-s是软过滤的意思，就是把不符合后面条件的variations打上标签，但不过滤掉；-g，-G这对参数是说，indel附近的indel或snp是不准确的，大多是假阳性，过滤掉，这里我设的10bp，这个值还是比较合理的；-i是保留后面符合条件的变异，刚好和-e相反，两者选其一，我这里用的-i编写过滤表达式<br><br>&emsp;&emsp;&emsp;&emsp;QUAL：基于Phred格式的表示ALT的质量，也可以理解为可靠性；可以理解为所call出来的变异位点的质量值。Q=-10lgP，Q表示质量值；P表示这个位点发生错误的概率。因此，如果想把错误率从控制在90%以上，P的阈值就是1/10，那lg（1/10）=-1，Q=（-10）*（-1）=10。同理，当Q=20时，错误率就控制在了0.01。这个参数其实和mpileup的-Q是重复的。<br><br>&emsp;&emsp;&emsp;&emsp;DP是碱基的覆盖深度，一般很多公司和课题组会选择10，但我这里选择的是6，本着宽进严出的原则，保留更多的阳性variations，10也是没有关系的。<br><br>&emsp;&emsp;&emsp;&emsp;MQ不同于MAPQ，是RMS Mapping Quality，公式定义如下：q指的是比对到这个参考基因组碱基上的比对质量，即MAPQ。参考之前说的，MAPQ设置为20，假设每个碱基的MAPQ都是20，则MQ为20。<br></p>
<p><img src="/2019/06/18/WGS分析笔记（4）- Call SNVs indels/MQ.png" alt="MQ"><br>&emsp;&emsp;&emsp;&emsp;参考上一篇里的MAPQ分布可以看到，使用bwa mem后，其实大多数的reads的MAPQ都在60，这样的话，MQ最好也就是60，但是在40有一个小突起，对于MQ的筛选，大家的选择可以酌情而定，50是一个大家使用较多的阈值点。<br><br><img src="/2019/06/18/WGS分析笔记（4）- Call SNVs indels/MAPQ%E5%88%86%E5%B8%83.png" alt="MAPQ分布图"><br><img src="/2019/06/18/WGS分析笔记（4）- Call SNVs indels/MAPQ%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E6%9B%B2%E7%BA%BF.png" alt="MAPQ累积分布曲线"><br>&emsp;&emsp;&emsp;&emsp;DP4分别是正反链上REF和ALT的深度，我用“DP4[2]+DP4[3]&gt;4”筛选ALT的深度至少是5的variations。<br></p>
<p>&emsp;&emsp;那么，以上的脚本其实是符合单个样本进行分析的，但如果是家系样本进行分析，其实是有问题的，因为在call这一步的时候用-v参数只输出变异位点，在获得了三个人的vcf文件进行merge的时候，对于一些变异（这些变异只存在于三个人的某一个或某两个），你就不知道不存在的那个人身上，是因为无变异还是没有覆盖到reads。这不利于做trio分析。那么要克服这个问题只需要去掉-v参数即可。<br></p>
<p>&emsp;&emsp;然后进行merge，是在完成了一个家系的call snp/indel以后。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ bgzip -c -f -@ 12 var.flt.vcf &gt; var.vcf.gz</span><br><span class="line"># 进行文件压缩;-c不改变内容; -f强制输出，存在就覆盖;-@线程数</span><br><span class="line">$ bcftools index -t var.vcf.gz</span><br><span class="line"># 建立索引，merge需要; -t建立tbi格式索引</span><br><span class="line">$ bcftools merge -Ov --force-samples -l file.list -o merge.var.vcf </span><br><span class="line"># 进行合成，-O输出文件格式,v表示vcf格式文件;</span><br><span class="line"># --force-samples，对于重名样本强制合成;-o输出文件</span><br><span class="line"># -l包含文件名的文件，一行一个文件名，将先证者放在第一位</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;之后可以用bcftools对结果做一下统计处理<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 统计结果plot-vcfstats</span><br><span class="line">$ bcftools stats -F/your/path/of/reference -s - merge.var.vcf &gt;  merge.var.vcf.stats &amp;&amp; \</span><br><span class="line">$ plot-vcfstats merge.var.vcf.stats -p vars_output</span><br><span class="line"># plot-vcfstats程序在bcftools下的misc目录中</span><br></pre></td></tr></table></figure>

<h3 id="DeepVariant"><a href="#DeepVariant" class="headerlink" title="DeepVariant"></a>DeepVariant</h3><p>&emsp;&emsp;谷歌提供了分别适用于WGS和WES的脚本，可供大家参考。我亲测了一下这个软件，速度有点慢……完全没有谷歌自己描述的那么快，做为尝鲜吧，把当时的脚本放上来，这里要特别感谢师姐的指导！虽然最后我也没打算用这个软件完成我的课题吧。<br><br>&emsp;&emsp;&emsp;&emsp;<a href="https://github.com/google/deepvariant/tree/r0.7/scripts" target="_blank" rel="noopener">https://github.com/google/deepvariant/tree/r0.7/scripts</a><br>&emsp;&emsp;Deepvariant无需安装，直接拉docker下来就行，不然要是安装，这个环境配置怕是要折磨死人的。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># docker安装，仅针对ubuntu用户</span><br><span class="line">	$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common </span><br><span class="line">	$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">	$ sudo apt-key fingerprint 0EBFCD88</span><br><span class="line">	$ sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class="line">	$ sudo apt-get update</span><br><span class="line">	$ sudo apt-get install docker-ce</span><br><span class="line">	$ sudo docker run hello-world</span><br><span class="line">	$ sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;拉取一下docker就可以使用deepvariant了<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull dajunluo/deepvariant</span><br><span class="line">$ sudo docker images</span><br><span class="line">$ sudo docker run -it dajunluo/deepvariant:latest</span><br><span class="line">$ sudo docker run -it --name deepvariant -v /you/path/of/refrence/dir/:/home/ref_hg19 -v /home/biowork/:/home/biowork dajunluo/deepvariant</span><br><span class="line"># -v是把我本地的数据对接到docker环境里，这个请自行根据需要对接</span><br><span class="line">$ nohup python /home/bin/make_examples.zip --mode calling --ref /you/path/of/refrence --reads //you/path/of/bam --examples example.gz &gt; 1.log &amp;</span><br><span class="line">$ nohup python /home/bin/call_variants.zip --outfile call_variants_output.gz --examples example.gz --checkpoint /home/models/model.ckpt &gt; 2.log &amp;</span><br><span class="line">$ nohup python /home/bin/postprocess_variants.zip --ref /you/path/of/refrence --infile call_variants_output.gz  --outfile output.vcf.gz &gt; 3.log &amp;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;之后便可以用bcftools或者gatk进行merge，对于这一步可以参考上面的gatk链接或者bcftools步骤。<br></p>
<hr>
<p>&emsp;&emsp;到了这一步就可以完了么？显然不是，你用上述两个方法或者参考黄老师的脚本用gatk得到的结果，如果你仔细看，就会发现。<br><br><img src="/2019/06/18/WGS分析笔记（4）- Call SNVs indels/vcf.png" alt="vcf示例"><br>&emsp;&emsp;这是什么鬼，这又是什么鬼，为什么有那么多的多等位位点，你要是去统计，会发现这样的多等位位点还挺多的，所以你还不能直接过滤。对于这些变异我们一般是不会考虑嵌合的，因为平均30X的WGS是没法检测出嵌合体的。那么对于这样的位点怎么去考虑分析呢？<br><br>&emsp;&emsp;比较便捷的方法就是用bcftools里面的norm工具了。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ bgzip -c -f -@ 12 merge.var.vcf &gt; merge.var.vcf.gz</span><br><span class="line"># 进行文件压缩;-c不改变内容; -f强制输出，存在就覆盖;-@线程数</span><br><span class="line">$ bcftools index -t merge.var.vcf.gz</span><br><span class="line"># 建立索引, -t建立tbi格式索引</span><br><span class="line">$ bcftools norm -Ov -m-any -f /you/path/of/refrence merge.var.vcf.gz &gt; norm.vcf</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;这样，多等位位点就变成了二等位位点了，便于后续的分析。今天的内容就到这里了，下一篇就是注释以及各种过滤了。<br></p>
<hr>
<p>&emsp;&emsp;水平有限，要是存在什么错误请评论指出，可发送邮件至<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>！请大家多多批评指正，相互交流，共同成长，谢谢！！！<br></p>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/18/WGS分析笔记（3）- bam文件的处理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/18/WGS分析笔记（3）- bam文件的处理/" class="post-title-link" itemprop="url">WGS分析笔记（3）- bam文件的处理</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-18 12:50:51 / 修改时间：13:11:52" itemprop="dateCreated datePublished" datetime="2019-06-18T12:50:51+08:00">2019-06-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>上一篇记录了mapping这一步的软件选择，也讲到了对于sam文件如何考虑MAPQ的过滤，这篇我主要想记录一下bam文件在进行call variation之前的处理。<br></p>
</li>
<li><p>包括MAPQ的筛选等都是这个处理的一部分。<br></p>
</li>
<li><p>既然要处理bam文件，不得不提bam文件的格式。<br></p>
</li>
<li><p>处理生物信息的数据时会发现，文件有各种各样的格式，眼花缭乱，这也是我一开始接触课题接触分析流程时的感受。但是多和这些文件打交道以后，会发现，大多数的不同格式的文件其本质都是文本文件，为了某种特殊的处理或记录需要，按一定的规则记录信息。包括之前接触的fasta、fastq文件，也包括sam文件，以后后面步骤会接触到的vcf文件等。<br></p>
</li>
<li><p>bam文件是sam文件的二进制格式，这里贴一张图，来说明一下为什么要转换成bam文件来处理。<br><br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/%E5%A4%A7%E5%B0%8F.png" alt="文件大小"></p>
</li>
<li><p>可以看到，不经过处理的sam文件是非常大的，非常不利于存储和处理，而转换格式后的bam文件小很多，所以很多处理软件也是针对bam文件进行开发的。<br></p>
</li>
<li><p>包括bwa，bowtie2的输出文件，都是sam文件，但是sam文件具体是什么样子的，我这里不会展开来讲，一是因为<a href="http://samtools.github.io/hts-specs/SAMv1.pdf" target="_blank" rel="noopener">官网说明书</a>已经说的很清楚了，二是因为你随手一个百度、谷歌（如果你翻得动墙）就有很多很多的人发帖介绍，而内容大体都是类似的，我自认为也没有什么能比他们讲得更好的。但是了解这个文件的内容确实是非常重要的。<br></p>
</li>
<li><p>以<code>@</code>开头的行记录了header信息，之后的行记录了每个reads的mapping信息，一般对于这样的sam文件我们要做的处理大体就是先转换为bam文件，进行sort，再进行merge，最后mark duplicates，并建立索引。接下来我将一步步介绍怎么去处理，以及为什么我是这么处理的。<br></p>
</li>
<li><p>在开始之间先使用<a href="http://www.htslib.org/doc/samtools.html" target="_blank" rel="noopener">samtools</a>对参考序列进行索引建立，作用是用于samtools软件快速识别，这一步也是一劳永逸的，只要不把索引文件删除。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ samtools faidx re.fa</span><br><span class="line"># 得到索引文件：re.fa.fai</span><br></pre></td></tr></table></figure>
</li>
<li><p>首先是把sam文件转换成bam文件，我们通过samtools view来实现，代码如下：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ samtools view -S in.sam -b &gt; out.bam</span><br><span class="line">$ samtools view -b in.bam -S &gt; out.sam</span><br></pre></td></tr></table></figure>
</li>
<li><p>但实际上，在真正的操作中，我们是不会保留sam文件的，甚至是不会产生sam文件的，因此，我们通常这么来写命令。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ bwa mem -t 12 -M -R &quot;@RG\tID:W2018001\tPL:ILLUMINA\tLB:W2018001\tSM:W2018001&quot; /your/path/of/reference/ucsc.hg19.fasta 1.fq.gz 2.fq.gz | samtools view -q 1 -Shb - &gt; W2018001.bam</span><br><span class="line"># 关于“|”之前的我就不解释了，看我上一篇简书</span><br><span class="line"># -q 1 ：筛选MAPQ用的，意为保留MAPQ &gt;= 1的记录，上一篇简书中讨论过关于MAPQ的由来和分布，这里用“1”也是保险起见，但实际上没啥区别，后期处理上（vcf处理），我们会以更严格的阈值去过滤</span><br><span class="line"># -h ：表示保留header信息</span><br><span class="line"># -S，-b：表示格式，S指的是sam格式，b指的是bam格式</span><br></pre></td></tr></table></figure>
</li>
<li><p>这样操作的好处是直接可以得到bam文件，不必占用大量的空间存储sam文件。如果你实在是需要sam文件也可以转换回去，但如果你只是想查看一下，也可以通过以下方式实现。还是很方便的。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ samtools view -h xxx.bam | less</span><br></pre></td></tr></table></figure>
</li>
<li><p>在测序的时候序列是随机打断的，所以reads也是随机测序记录的，进行比对的时候，产生的结果自然也是乱序的，为了后续分析的便利，将bam文件进行排序。事实上，后续很多分析都建立在已经排完序的前提下。关于排序可以通过以下命令完成。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ samtools sort -@ 6 -m 4G -O bam -o sorted.bam W2018001.bam</span><br><span class="line"># @：线程数</span><br><span class="line"># m：每个线程分配的最大内存</span><br><span class="line"># O：输出文件格式</span><br><span class="line"># o：输出文件的名字</span><br><span class="line"># 输入文件放在最后</span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来要做的是merge，这个不是所有的样本都需要做的！！！<br></p>
</li>
<li><p>之前有提到，WGS的数据比较大，对于一个样本可能有多对文件，一般有两个思路，一个是先对原始的fastq文件进行merge，一个是对后面的bam文件进行merge。那么我选用的是后者。实现脚本如下：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ samtools merge -@ 6 -c sorted.merged.bam *.sorted.bam</span><br><span class="line"># @：线程数</span><br><span class="line"># c：当输入bam文件的header一样时，最终输出一个header</span><br><span class="line"># 当然也可以用-h file，定义你想要的header，file里的内容就是sam文件header的格式</span><br><span class="line"># 第一个bam是输出的文件名，后面排列输入的文件名，我这里用了通配符‘*’，要保证该目录下‘.sorted.bam’结尾的都是你要输入的文件</span><br><span class="line"># 当然也可以用-b file，file文件里罗列要merge的文件名，一行一个文件名</span><br></pre></td></tr></table></figure>
</li>
<li><p>下一步就是remove duplicates，为什么要进行这一步呢？先来说一下测序，我们都知道人的基因组是很庞大的（约30亿个碱基对），在测序的时候，先会把基因组的DNA序列通过超声震荡随机打断成150bp的片段，那么从概率上来讲，出现同样的片段（开始和结束位置都一样）的几率是极小的。但是由于PCR对某些位置有偏好的扩增，会导致一些一模一样的reads存在。这些reads其实是一个片段的扩增导致的，多出来的reads，对该区段突变的判断是没什么贡献的，如果不加处理，反而会大大增加那个位置的深度，导致某些结果的不准确。<br></p>
</li>
<li><p>如下图所示，箭头所指的reads，就是duplicates，我们一般采取的策略是标记或者去除，这样的话，下一步call variation的时候会不考虑这些reads。<br><br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/duplicates2.png" alt="duplicates(from bing)"></p>
</li>
<li><p>关于这一步，有很多软件可以实现，比较多用的是picard和samtools rmdup。我这里用的是GATK包里集成的picard的MarkDuplicates。关于picard和samtools rmdup的效果其实大家可以自己试一下，我很早之前做过的试验是，samtools rmdup速度很快，但是去除的效果稍差。大家用的最多的也是picard。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ java -jar /you/path/of/gatk/gatk-package-4.0.10.1-local.jar \</span><br><span class="line">	MarkDuplicates \</span><br><span class="line">	-INPUT sorted.merged.bam \</span><br><span class="line">	-OUTPUT sorted.merged.markdup.bam \</span><br><span class="line">	-METRICS_FILE markdup_metrics.txt</span><br><span class="line"># 也可以加上“REMOVE_DUPLICATES=true”来去除掉这些duplicates，不然就只是标记</span><br></pre></td></tr></table></figure>
</li>
<li><p>到了这一步基本上就处理的差不多了，可以进行call variation了，但是这里还有一步建立索引，这十分的重要！！！！<br></p>
</li>
<li><p>必须对bam文件进行排序后，才能进行index，否则会报错。建立索引后将产生后缀为.bai的文件，用于快速的随机处理。很多情况下需要有bai文件的存在，特别是显示序列比对情况下。建立索引很简单。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ samtools index sorted.merged.markdup.bam</span><br></pre></td></tr></table></figure>
</li>
<li><p>到了这一步就基本上完事了，可以通过IGV或tview来查看情况，这都需要建立索引，且索引文件和bam文件在同一个目录下。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ samtools tview sorted.merged.markdup.bam re.fa</span><br><span class="line"># 可以用-p chr:pos（加在tview和sorted.merged.markdup.bam之间）指定要查看的位置</span><br><span class="line"># 也可以进去后用敲‘g’输入`chr10:10,000,000&apos; 或 `=10,000,000&apos;查看指定的位置，敲&apos;?&apos;了解更多说明，q退出</span><br></pre></td></tr></table></figure>
</li>
<li><p>下图就是效果了，用“？”，打开左边的帮助界面，其中圆点表示正链比对，逗号表示负链比对，星号表示插入。不同的颜色代表不同的含义，具体怎么调看帮助框。要是觉得不好看的话可以用IGV查看。IGV的效果就是上图duplicates的效果。<br><br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/tview.png" alt="tview"></p>
</li>
<li><p>同时对于得到的bam文件也可以进行一下查看，对于bam的统计软件就更多了，我这里网罗了一些帖子上的推荐以及我自己日常使用的软件，感兴趣的可以自己去下载来使用一下。<br></p>
</li>
</ul>
<p>###<a href="http://www.htslib.org/doc/samtools.html" target="_blank" rel="noopener">samtools</a></p>
<ul>
<li><p>这是个强大的软件，也自带一些统计工具，上篇简书其实我们就用到了，主要是四个：idxstats，depth，stats，flagstat<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">$ samtools depth sorted.merged.markdup.bam</span><br><span class="line">	示例结果</span><br><span class="line">		#chr    pos depth</span><br><span class="line">		chr1    1   5</span><br><span class="line">	结果可以得到染色体名称、位点位置、覆盖深度</span><br><span class="line">	-a:输出所有位点，包括零深度的位点</span><br><span class="line">	-a -a --aa:完全输出所有位点，包括未使用到的参考序列</span><br><span class="line">	-b FILE：计算BED文件中指定位置或区域的深度</span><br><span class="line">	-f FILE：指定bam文件</span><br><span class="line">	-l INT:忽略小于此INT值的reads</span><br><span class="line">	-q INT：只计算碱基质量大于此值的reads</span><br><span class="line">	-Q INT：只计算比对质量大于此值的reads</span><br><span class="line">	-r CHR:FROM-END：只计算指定区域的reads</span><br><span class="line">$ samtools idxstats sorted.merged.markdup.bam  #需要预先进行sort和index</span><br><span class="line">	示例结果</span><br><span class="line">		#ref    sequence_length mapped_reads    unmapped_reads</span><br><span class="line">		chr1    195471971    6112404    0</span><br><span class="line">	结果可看出，分别统计染色体名称、序列长度、mapped数目，以及unmapped数目</span><br><span class="line">$ samtools flagstat sorted.merged.markdup.bam</span><br><span class="line">	示例结果：</span><br><span class="line">		20607872 + 0 in total (QC-passed reads + QC-failed reads) #总共的reads数</span><br><span class="line">		0 + 0 duplicates #重复reads的数目</span><br><span class="line">		19372694 + 0 mapped (94.01%:-nan%) #总体上reads的数目以及匹配率；可能有有小偏差</span><br><span class="line">		20607872 + 0 paired in sequencing  #paired reads的数目</span><br><span class="line">		10301155 + 0 read1 #reads1的数目</span><br><span class="line">		10306717 + 0 read2 #reads2的数目</span><br><span class="line">		11228982 + 0 properly paired (54.49%:-nan%) #完美匹配的reads数：比对到同一条参考序列，并且两条reads之间的距离符合设置的阈值</span><br><span class="line">		18965125 + 0 with itself and mate mapped#两条都比对到参考序列上的reads数，但是并不一定比对到同一条染色体上</span><br><span class="line">		407569 + 0 singletons (1.98%:-nan%)#只有一条比对到参考序列上的reads数，和上一个相加，则是总的匹配上的reads数。</span><br><span class="line">		3059705 + 0 with mate mapped to a different chr#两条分别比对到两条不同的染色体的reads数</span><br><span class="line">		1712129 + 0 with mate mapped to a different chr (mapQ&gt;=5)#两条分别比对到不同染色体的且比对质量值大于5的数量</span><br><span class="line">	# 说明：</span><br><span class="line">		1.bwa的mem比对方法生成的bam文件保留sencondly比对的结果。所以使用flagstat给出的结果会有偏差。</span><br><span class="line">		2.每一项统计数据都由两部分组成，分别是QC pass和QC failed，表示通过QC的reads数据量和未通过QC的reads数量。以“PASS + FAILED”格式显示</span><br><span class="line">$ samtools stats sorted.merged.markdup.bam</span><br><span class="line"> 	# 对bam文件进行详细的统计，也可只统计某一染色体的某一区域chr：from-to</span><br><span class="line">	结果包括：</span><br><span class="line">		Summary Numbers,raw total sequences,filtered sequences, reads mapped, reads mapped and paired,reads properly paired等信息</span><br><span class="line">		Fragment Qualitites #根据cycle统计每个位点上的碱基质量分布</span><br><span class="line">		Coverage distribution #深度为1，2，3，，，的碱基数目</span><br><span class="line">		ACGT content per cycle #ACGT在每个cycle中的比例</span><br><span class="line">		Insert sizes #插入长度的统计</span><br><span class="line">		Read lengths #read的长度分布</span><br><span class="line">	stats出来的结果可以使用plot-bamstats来画图(samtools目录下misc目录中)</span><br><span class="line">	$ plot-bamstats -p outdir/ sorted.merged.markdup.bam.stats</span><br></pre></td></tr></table></figure>
</li>
<li><p>下图就是plot-bamstats操作的输出结果了，可以看到有很多的图。效果还是很好的。<br><br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/plot-bamstats.png" alt="plot-bamstats"></p>
</li>
<li><p>更多关于samtools的工具以及上文提到的工具的其余参数请参考官网：<a href="http://www.htslib.org/doc/samtools.html" target="_blank" rel="noopener">http://www.htslib.org/doc/samtools.html</a><br></p>
</li>
</ul>
<p>###<a href="https://rseqc.sourceforge.net/" target="_blank" rel="noopener">RSeQC</a></p>
<ul>
<li>这也是上篇中提到过的，所以安装方式和使用就不赘述了，其实里面还有一些其余实用的工具，当然这款软件的最初使用对象是RNA-seq，但并不影响使用，有些工具是通用的，有一点要注意的是，bam_stat.py里的unique mapping的默认阈值是MAPQ&gt;=30，当然可以通过参数来修改，这个在结果的理解上大家要注意。<br></li>
</ul>
<p>###<a href="https://bedtools.readthedocs.io/en/latest/" target="_blank" rel="noopener">bedtools</a></p>
<ul>
<li><p>这是一个经常使用也很实用的软件，我经常会用来截取bam然后在igv上看突变的情况，师姐推荐其中的mutlicov进行覆盖度的统计。我粗略的看了一下bedtools的说明书，用于coverage统计的应该还有coverage，genomecov。感兴趣的可以尝试一下。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bedtools:</span><br><span class="line">	$ wget https://github.com/arq5x/bedtools2/releases/download/v2.27.1/bedtools-2.27.1.tar.gz</span><br><span class="line">	$ tar -zxvf bedtools-2.27.1.tar.gz</span><br><span class="line">	$ cd bedtools2</span><br><span class="line">	$ make</span><br><span class="line"># 脚本在bin/下的bedtools</span><br><span class="line"># Ubuntu用户也可以使用下述命令来下载：</span><br><span class="line">$ sudo apt-get install bedtools</span><br></pre></td></tr></table></figure>
</li>
<li><p>截取bam文件，查看igv可以用以下命令：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ bedtools intersect -a sorted.merged.markdup.bam -b region.sorted.bed &gt; target_reads.bam &amp;&amp; samtools index target_reads.bam </span><br><span class="line">#其中bed文件的格式可以参考：</span><br><span class="line">#染色体号  起始位置  终止位置</span><br><span class="line">chr1	226173187	226173247</span><br><span class="line">#用&quot;\t&quot;分隔</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>###<a href="https://software.broadinstitute.org/gatk/" target="_blank" rel="noopener">GATK</a></p>
<ul>
<li>GATK不仅可以call variation，里面还包含了很多其他用途的工具包，其中有一个工具叫DepthOfCoverage，可以统计depth和coverage，但是在panel中比较适用，因为有bed范围，且比较小。这个工具的速度是比较慢的，要在全基因组上做不太现实。所以我本人也没去使用。<br></li>
</ul>
<p>###<a href="http://bamstats.sourceforge.net/" target="_blank" rel="noopener">BAMStats</a></p>
<ul>
<li>一款比较早的bam统计软件，没用过，但是看说明使用是极其简单了，说一下怎么安装。感兴趣的可以自己试一下，很简单。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://jaist.dl.sourceforge.net/project/bamstats/BAMStats-1.25.zip</span><br><span class="line">$ unzip BAMStats-1.25.zip</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>###<a href="https://github.com/shiquan/bamdst" target="_blank" rel="noopener">bamdst</a></p>
<ul>
<li><p>一款简单好用的深度统计软件。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/shiquan/bamdst.git</span><br><span class="line">$ cd bamdst/</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装好后，需要准备.bed文件及.bam文件，以软件提供的MT-RNR1.bed和test.bam为例，使用命令如下：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bamdst -p MT-RNR1.bed -o ./ test.bam</span><br></pre></td></tr></table></figure>
</li>
<li><p>输出的结果包含7个文件，为：<br></p>
<ul>
<li>-coverage.report</li>
<li>-cumu.plot</li>
<li>-insert.plot</li>
<li>-chromosome.report</li>
<li>-region.tsv.gz</li>
<li>-depth.tsv.gz</li>
<li>-uncover.bed</li>
</ul>
</li>
<li><p>主要看一下coverage.report文件，里面包含了大量信息。<br></p>
</li>
</ul>
<p>###<a href="http://qualimap.bioinfo.cipf.es/doc_html/index.html" target="_blank" rel="noopener">qualimap</a></p>
<ul>
<li><p>这算是压轴了吧，这个软件是我师姐推荐的，安装使用都比较容易，给出的是PDF或HTML的报告，报告中的信息特别丰富，还有一堆的图，所以在我自己的脚本中也会对每个样本使用该软件统计，简述一下安装和使用。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 第一步：下载</span><br><span class="line">$ mkdir qualimap</span><br><span class="line">$ cd qualimap</span><br><span class="line">$ wget https://bitbucket.org/kokonech/qualimap/downloads/qualimap_v2.2.1.zip</span><br><span class="line">$ unzip qualimap_v2.2.1.zip</span><br><span class="line">$ cd qualimap_v2.2.1</span><br><span class="line"># 第二步安装相关的软件</span><br><span class="line"># java</span><br><span class="line"># 这个应该都有，这里就是贴一下官网的步骤</span><br><span class="line">$ sudo apt-get install openjdk-6-jre</span><br><span class="line"># R</span><br><span class="line"># 官网上也有，我贴的是自己以前安装的记录</span><br><span class="line">$ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9</span><br><span class="line">$ apt-get update</span><br><span class="line">$ apt-get install r-base</span><br><span class="line">$ apt install r-base-core</span><br><span class="line"># R包安装，两个方法，第一个听说容易报错，我用的是第二个</span><br><span class="line">$ Rscript scripts/installDependencies.r</span><br><span class="line"># 或</span><br><span class="line">$ R</span><br><span class="line">&gt; install.packages(&quot;optparse&quot;)</span><br><span class="line">&gt; source(&quot;http://bioconductor.org/biocLite.R&quot;)</span><br><span class="line">&gt; biocLite(c(&quot;NOISeq&quot;, &quot;Repitools&quot;, &quot;Rsamtools&quot;, &quot;GenomicFeatures&quot;, &quot;rtracklayer&quot;))</span><br><span class="line">&gt; q()</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用也简单，主要分为带gtf文件和不带gtf文件，全基因组的话一般不带gtf文件，然后bamqc其实也只是这个软件中的一个工具，其他的工具感兴趣的也可以看看。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ qualimap bamqc -bam sorted.merged.markdup.bam  --java-mem-size=20G -c -nt 16 -outdir bamqc -outfile bamqc.pdf -outformat PDF:HTML</span><br><span class="line"># 参数也没有什么特别要注意的，基本上默认的就可以</span><br></pre></td></tr></table></figure>
</li>
<li><p>找了一个示例结果，发现有23页，我这里就不贴了，大家可以自己尝试一下。<br></p>
</li>
<li><p>最后贴两张图，是我自己写的脚本得到的深度分布，累积曲线以及覆盖率，因为是自己写的，所以比较糙，横纵坐标标题什么的一律没写。<br><br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/depth.png" alt="depth"></p>
</li>
<li><p>上图可以看到，深度分布还是比较正态的，最多的30X左右，至于左边0X为什么这么高，是因为参考基因组有些位置就是N，还有一些位置就是我的样本没有覆盖到。<br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/depth.cdf.png" alt="depth.cdf"></p>
</li>
<li><p>上图可以看到，小于10X的数据的不到2%，超过50%的数据都是高于30X的，还是不错的。<br><img src="/2019/06/18/WGS分析笔记（3）- bam文件的处理/coverage.png" alt="coverage"></p>
</li>
<li><p>上图我按不同的染色体进行统计覆盖率，去掉了其余的一些未知染色体位置的序列上的信息（这个信息具体要了解参考基因组的特性，比如有些序列目前能明确在人身上，却不知道具体在哪个染色体等，这些信息也是包含在参考基因组中的，仔细看参考基因组会发现，除了22条常染色体，2条性染色体，还有很多其他的序列），这个覆盖率并不是我想想的那般全体高于99%，也没公司给的报告描述的那么好，主要是因为MAPQ的过滤导致了这样的结果，但是总体的覆盖率还可以。</p>
</li>
<li><p>水平有限，要是存在什么错误请评论指出，可发送邮件至<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>！请大家多多批评指正，相互交流，共同成长，谢谢！！！</p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/" class="post-title-link" itemprop="url">WGS分析笔记（2）- bwa vs bowtie2</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-18 11:10:20 / 修改时间：12:53:49" itemprop="dateCreated datePublished" datetime="2019-06-18T11:10:20+08:00">2019-06-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>在进行正式的mapping记录之前，先记录一下bwa与bowtie2在mapping这个环节的情况。<br></p>
</li>
<li><p>一般对于WGS结果的mapping，一般推荐的软件有两款，分别是bwa和bowtie2，大多数的公司报告或者网上的教程，我所看到的都是使用bwa进行比对的，这里，我来进行一下两个软件的对比。<br></p>
</li>
<li><p>实验对象还是之前文章提到的那个样本的数据，我只取用其中的一对数据进行mapping并比较。<br></p>
</li>
<li><p>比较之前先进行一下软件安装、参考序列下载并建立索引<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bowtie2</span><br><span class="line">	$ wget https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.3.4.3/bowtie2-2.3.4.3-linux-x86_64.zip</span><br><span class="line">	# https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.3.4/bowtie2-2.3.4-linux-x86_64.zip</span><br><span class="line">	$ unzip bowtie2-2.2.9-linux-x86_64.zip</span><br><span class="line">	$ ln -sf /biosoft/bowtie2-2.3.4.3-linux-x86_64/bowtie2 /home/shiyuantong/bin/bowtie2</span><br><span class="line">BWA:</span><br><span class="line">	$ wget https://sourceforge.net/projects/bio-bwa/files/bwa-0.7.17.tar.bz2</span><br><span class="line">	$ tar -jxvf bwa-0.7.17.tar.bz2 # x extracts, v is verbose (details of what it is doing), f skips prompting for each individual file, and j tells it to unzip .bz2 files</span><br><span class="line">	$ make</span><br></pre></td></tr></table></figure>
</li>
<li><p>关于安装这里有一些需要注意的地方！！！！！<br></p>
</li>
<li><p>首先是bowtie2，建议大家使用2.3.4的下载链接，我在下载的时候最新版是2.3.4.3，但是在使用的出现了报错！！！！！<br></p>
</li>
<li><p>报错的内容如下（当时没截图）：<br><br>&emsp;&emsp;&emsp;&emsp;Segmentation fault (core dumped) (ERR): bowtie2-align exited with value 139</p>
</li>
<li><p>这个报错只会出现在批量处理的脚本中，对单个样本的处理并没有影响，但是实际使用的时候，大家都是批量处理样本，怎么可能一个样本一个命令，因此推荐2.3.4的版本，当然，下面的比较不会涉及这个问题。<br></p>
</li>
<li><p>还有就是BWA了，这个软件ubuntu用户也可以直接使用<code>sudo apt-get install bwa</code>命令进行安装，我看了一下，两种方法的版本是一致的，都是0.7.17。<br></p>
</li>
<li><p>然后是参考序列，这里直接使用ucsc的hg19，下载与建立索引方式如下，根据自己的需要调整目录<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hg19：</span><br><span class="line">	$ cd /your/path/of/reference/</span><br><span class="line">	$ wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz</span><br><span class="line">	$ tar zvfx chromFa.tar.gz</span><br><span class="line">	$ cat *.fa &gt; hg19.fa</span><br><span class="line">	$ rm chr*.fa</span><br><span class="line">建立bwa索引：</span><br><span class="line">	$ bwa index -a bwtsw  hg19.fa</span><br><span class="line"> 	# 产生.bwt .pac .ann .amb .sa五个新文件</span><br><span class="line">	# -a：两种构建index算法，bwtsw以及is，bwtsw适用大于10MB的参考基因组，比如人，is适用于小于2GB的数据库，是默认的算法，速度较快，需要较大的内存，</span><br><span class="line">	# -p：输出数据库的前缀，默认与输入文件名一致，这里我没有加这个参数，直接输出到当前目录</span><br><span class="line">建立bowtie2索引：</span><br><span class="line">	$ bowtie2-build hg19.fa hg19.fa</span><br><span class="line">	# bowtie2-build命令在安装bowtie2的目录下找到</span><br><span class="line">	# 第一个hg19.fa代表输入的参考序列</span><br><span class="line">	# 第二个hg19.fa代表输出的索引文件前缀</span><br><span class="line">	# 产生六个.bt2新文件</span><br></pre></td></tr></table></figure>
</li>
<li><p>上述程序建立索引速度较慢，尤其是bowtie2，但是一次建好，一劳永逸，请大家耐心等待，也可以放在后台，防止终端突然的中断。<br></p>
</li>
<li><p>建立好索引就可以直接开始比对了，以下是我的比对程序，都开了24线程，用<code>nohup …… &amp;</code>放在后台运行，用<code>time</code>记录时间。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ nohup time bowtie2 -p 24 -x /your/path/of/reference/ucsc.hg19.fasta --rg-id W2018001 --rg PL:ILLUMINA --rg LB:W2018001 --rg SM:W2018001 -1 W2018001_NZTD180602206_HCV5MDMXX_L1.cleaned.1.fq.gz -2 W2018001_NZTD180602206_HCV5MDMXX_L1.cleaned.2.fq.gz -S W2018001.bowtie2.sam &gt; W2018001.bowtie2.log &amp;</span><br><span class="line">$ nohup time bwa mem -t 24 -M -R &quot;@RG\tID:W2018001\tPL:ILLUMINA\tLB:W2018001\tSM:W2018001&quot; /your/path/of/reference/ucsc.hg19.fasta W2018001_NZTD180602206_HCV5MDMXX_L1.cleaned.1.fq.gz W2018001_NZTD180602206_HCV5MDMXX_L1.cleaned.2.fq.gz 1&gt;W2018001.bwa.sam 2&gt;W2018001.bwa.log &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>这一步会比较久，我也是经过漫长的半天等待终于迎来了结果，首先看一下速度吧。先前的脚本使用了<code>time</code>的命令，可以直接看到速度，在日志文件里。<br><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/%E6%97%B6%E9%97%B4%E5%AF%B9%E6%AF%94.png" alt="时间对比"></p>
</li>
<li><p>日志文件的最后两行就是<code>time</code>命令输出的结果，所以没有必要用<code>cat</code>查看，而且bwa的日志文件，要是用<code>cat</code>怕是屏幕要炸。图中可以看到两个红色的框，就是我标出来的时间。（其实我原来用<code>time</code>命令，结果不长这样的，这个结果不太利于观看，但是也能说明问题了）<br></p>
</li>
<li><p>很明显的可以看到半套全基因组的数据（我只用了样本一半的数据）bowtie2跑的更快一些，但其实大家不用纠结这个点。因为上一次我用24线程，一样的脚本一样的数据，跑bowtie2花了六个多小时，速度没有bwa快，同时以前在使用酵母的测序数据（数据量会比较小）的时候，明显发现bwa速度比bowtie2快，甚至在说法上你也会发现不同的人给你的说法是不一样的，有些人说bwa快有些人说bowtie2快，网上看帖子也没有一个十分明确的说法哪个速度快。这里大家完全可以用自己的数据和脚本跑一下，看看结果。<br></p>
</li>
<li><p>接下来我想看看比对效果，这里我先采用了samtools的flagstat分别进行统计，下面是安装samtools的步骤：<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">samtools:</span><br><span class="line">	$ wget https://github.com/samtools/samtools/releases/download/1.9/samtools-1.9.tar.bz2</span><br><span class="line">	$ tar xvfj samtools-1.9.tar.bz2</span><br><span class="line">	$ cd samtools-1.9</span><br><span class="line">	$ ./configure --prefix=/where/to/install</span><br><span class="line">	$ make</span><br><span class="line">	$ make install</span><br><span class="line"># samtools其实我到现在为止装的最崩溃的软件之一了，因为在实际安装的时候你会发现它需要各种各样的库的支持，对于使用新机器的我，我基本是安装，报错缺什么库，安装缺的库，重新安装，这么折腾了一下午</span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来就是使用统计工具，其实很简单。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ samtools flagstat W2018001.bowtie2.sam &gt;W2018001.bowtie2.flagstat</span><br><span class="line">$ samtools flagstat W2018001.bwa.sam &gt;W2018001.bwa.flagstat</span><br></pre></td></tr></table></figure>
</li>
<li><p>这个也需要花一点时间，但不会太长，看一下结果。<br><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/flagstat.png" alt="flagstat"></p>
</li>
<li><p>这个结果还是比较清楚的，bwa的结果比bowtie2稍稍好一点。但相差不是很大，所以对于这两个软件，一直是公说公有理，婆说婆有理，这里我用另一个软件对结果进行统计，再进行对比试试。<br></p>
</li>
<li><p><a href="https://rseqc.sourceforge.net" target="_blank" rel="noopener">RSeQC</a>是一个功能强大的软件，里面有很多实用的小工具，其中的bam_stat就是一个实用的bam/sam结果统计工具，安装方式也是相当简单了，就是一个python的包，支持python2.x和python3.x，这里我选用python3的pip来安装，因为本人习惯使用python3。<br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install RSeQC</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用和结果如下，由于我这个sam文件比较大，运行起来比较慢，所以我开了俩终端。<br><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bam_stat.png" alt="bam_stat"></p>
</li>
<li><p>其实我最想看的unique mapping的reads，因为后期为了降低假阳性，在处理bam文件的时候会选择unique mapped的reads，但是在查看说明书无果后，找遍论坛没有找到一个能够说服我的筛选unique mapped的方式。<br></p>
</li>
<li><p>有这么几个方式，一个说是看tag，但是bwa的结果，你仔细看说明书和结果，会发现，这个tag并没有什么用，bowtie2倒是还可以。<br></p>
</li>
<li><p>第二个也是说的比较多的一个，看MAPQ。那么mapq是啥呢，我来贴几张图。<br></p>
</li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bowtie2%E7%9A%84%E8%AF%B4%E6%98%8E.png" alt="bowtie2的说明"></p>
<p><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/SAM%E7%9A%84%E8%AF%B4%E6%98%8E.png" alt="SAM的说明"></p>
<p><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/%E5%AE%98%E7%BD%91%E8%AF%B4%E6%98%8E.png" alt="官网说明"></p>
<ul>
<li>分别是sam格式官网的说明，bowtie2官网的说明，这两个说明的公式是一样的，都指向最后一个官网的说明。看到这个官网的公式，我直接就傻掉了，反正到现在也没推出个所以然来。但是前两张图就很好理解了。但是和很多人说的MAPQ&gt;=1就是unique mapping，我觉得是对不上的。对于这点我不多说，<a href="http://qiubio.com/archives/3321" target="_blank" rel="noopener">这里</a>的解释也是目前为止我最能接受的。<br></li>
<li>那上面那个结果，bam_stat，我在阅读源码后，发现是以MAPQ&gt;=30作为阈值来挑选是否unique的。由于bwa和bowtie2的mapq的计算方式不一样，这个结果其实并不可信。于是我写了一个脚本，看了一下mapq的分布情况。<br></li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bowtie2.png" alt="bowtie2"></p>
<p><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bwa.png" alt="bwa"></p>
<ul>
<li><p>这个图能说明什么呢，有待商榷。<br></p>
</li>
<li><p>这个时候再回过来看一下bowtie2的输出结果和大家说的bowtie2的筛选unique mapping的方法以及结果。<br><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bowtie2.log.png" alt="bowtie2.log"><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/bowtie2_tag.png" alt="bowtie2_tag"></p>
</li>
<li><p>其实到这里我也不知道该怎么办了，到现在还是不知道，bwa结果用mapq&gt;=1是否能得到unique mapping。这个结果对于后续分析影响有多大我不好说，至于怎么选择，我也不发表意见，不过在后续的筛选中，gatk给出的建议是mapq&gt;=40。<br></p>
</li>
<li><p>2019-1-9补充bwa结果，按mapq分布，分别计算&gt;=1,10,20,30的比例。为大家选择MAPQ作为筛选提供一个参考。<br><br><img src="/2019/06/18/WGS分析笔记（2）- bwa vs bowtie2/mapq%E5%88%86%E5%B8%83.png" alt="MAPQ比例"></p>
</li>
<li><p>但是回归主题，bwa和bowtie2，我决定选择bwa。<br></p>
</li>
<li><p>水平有限，要是存在什么错误请评论指出，可发送邮件至<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>！请大家多多批评指正，相互交流，共同成长，谢谢！！！<br></p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/" class="post-title-link" itemprop="url">WGS分析笔记（1）- 原始数据以及质控</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-18 00:23:29 / 修改时间：11:02:33" itemprop="dateCreated datePublished" datetime="2019-06-18T00:23:29+08:00">2019-06-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>二代测序方式分为三种：<br></p>
<ul>
<li><em>single read 单端测序</em><br></li>
<li><em>paired-end read 双端测序</em><br></li>
<li><em>mate-pair read 配对测序</em><br></li>
</ul>
</li>
<li><p>虽然有三种方式，但是大多数数据（包括本课题）为双端测序，至于三者之间的差别、优缺点以及适用场合可以自行搜索。<br></p>
</li>
<li><p>接下来讲的内容都是基于双端测序的。<br></p>
</li>
<li><p>测序仪原始下机的数据我们称为raw data，二代测序是将DNA片段打断了再测的，每个测序片段我们称为read，质控完的数据称为clean data。既然是双端测序，那么文件就是成对出现的，分别记录reads两端的信息：一般的命名是*.fq1.gz、*.fq2.gz（’ * ‘ 表示通配符），这是一个fastq文件，通常以fq或fastq作为后缀，具体内容下方会介绍。这里我给大家展示我们课题的一个真实数据，给大家看看大小以及命名方式。<br><br><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E5%B1%95%E7%A4%BA.png" alt="原始数据展示"></p>
</li>
<li><p>我们可以看到，首先我把我的用户名打码了，呵呵，开个玩笑。<br></p>
</li>
<li><p>首先这个样本总共有五个文件，这就是公司给的原始数据，我原封不动的上传到了我的服务器上，也没改名也没怎样，我在图片上画了五个蓝色的框，下面是分别代表的意思：<br></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">W2018001：是样本的名字，其实我一开始提交给公司的名字是2018001，为什么多了个W我也不知道啊。</span><br><span class="line">NZTD...：这一串是公司自动生成的编号，他们内部使用的，不知道也不需要知道啥意思，不同的公司，可能没有这个</span><br><span class="line">HCV...：flowcell_ID的信息，一般情况下一个样本是一样的</span><br><span class="line">L1：flowcell_lane的信息，图中有L1和L2，这也是为什么一个数据他给我四个文件的原因，他在不同的lane上测的，这里还要注意的一点就是，这个lane的值可能是同一个，就是即使碰到都是L1也是可能的</span><br><span class="line">1，2：分别代表reads的两端</span><br></pre></td></tr></table></figure>

<ul>
<li>我们可以看到，这个30X的WGS的数据量还是很大的，所以为什么他会是压缩文件，不同公司给的命名可能不一样，不过大体不会相差太多，具体命名的含义也可以问问公司的。<br></li>
<li>这里给到的是一个样本2对文件，实际情况是，可能有多对或者只有一对文件，对于这样的情况，我们的处理方式一般是看作一个文件处理，就是merge一下，有见过有些课题组是在这一步直接merge，我的处理方式是后期bam文件再merge。<br></li>
<li>好了，拿到这么一个数据，我们做的第一件事情应该是校验数据的完整性！！！这点很重要，即使一般情况下，传输都不会出错，但这一步还是要做的，怎么去做呢，就看这个截图里的第一个文件MD5.txt，其实这就是一个文本文件，打开了看看是这样的<br></li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/MD5%E4%BF%A1%E6%81%AF.png" alt="MD5信息"></p>
<ul>
<li>就是这样的四行信息，也就是一个文件名对应一个校验码，最简单的校验方式，linux系统自带的MD5校验命令：<br></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ md5sum -c MD5.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>这个还是需要一点点时间的，大家要耐心等待。展示一下我这里的结果吧（其实在上传完数据的时候我就校验过）<br></li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/%E6%A0%A1%E9%AA%8C%E7%BB%93%E6%9E%9C.png" alt="校验结果"></p>
<hr>
<ul>
<li><p>好了，校验完了，没问题，那么就给大家介绍一下文件的格式。<br></p>
</li>
<li><p>文件是什么呢，其实就是文本文件，可以直接查看，以下是示例：<br><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/fastq%E6%A0%BC%E5%BC%8F.png" alt="fastq格式"></p>
</li>
<li><p>一条read一条记录，一条记录占四行，第一行是注释，第二行是序列，就是我们所说的ATCG碱基序列，第三行是‘+’，第四行是对应的每个碱基的测序质量，也就是fastq中的“q”。每条记录之间是没有空格的。<br></p>
</li>
<li><p>贴一下关于第一行的解释<br></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>EAS139</th>
<th>The unique instrument name</th>
</tr>
</thead>
<tbody><tr>
<td>136</td>
<td>Run ID</td>
</tr>
<tr>
<td>FC706VJ</td>
<td>Flowcell ID</td>
</tr>
<tr>
<td>2</td>
<td>Flowcell lane</td>
</tr>
<tr>
<td>2104</td>
<td>Tile number within the flowcell lane</td>
</tr>
<tr>
<td>15343</td>
<td>‘x’-coordinate of the cluster within the tile</td>
</tr>
<tr>
<td>197393</td>
<td>‘y’-coordinate of the cluster within the tile</td>
</tr>
<tr>
<td>1</td>
<td>Member of a pair, 1 or 2 (paired-end or mate-pair reads only)</td>
</tr>
<tr>
<td>Y</td>
<td>Y if the read fails filter (read is bad), N otherwise</td>
</tr>
<tr>
<td>18</td>
<td>0 when none of the control bits are on, otherwise it is an even number</td>
</tr>
<tr>
<td>ATCACG</td>
<td>Index sequence</td>
</tr>
</tbody></table>
<ul>
<li><p>第一个是测序机器ID，独一无二的，你可以去illumina官网查到的（我没查过）<br></p>
</li>
<li><p>第二个是这个机器跑的次数，一般机器都是有使用寿命的，所以次数越多肯定结果越差，那么一般在什么区间合适呢，我的老师给的建议是200-9999，为啥还有下限呢，那是因为，机器刚开始跑的那几次，需要磨合嘛，不是很准。看来这个展示数据不是很好啊，吓得我赶紧去看了下我的数据，还好，在212次（懒得贴图了，hexo弄个图比简书还麻烦），在范围内。<br></p>
</li>
<li><p>倒数第三个，表示数据有没有被过滤过，一般我们的原始数据肯定是N的，要是给的原始数据是Y，你就得好好问问公司原因了。<br></p>
</li>
<li><p>其余具体的我就不解释了，有问题可以评论交流。<br></p>
</li>
<li><p>第二行要注意的是，可能有N的出现，那是因为有些碱基没被测出来。<br></p>
</li>
<li><p>第四行是ASCII码表示的碱基质量，这样就能保证质量是用一个字符表示的，和碱基一一对应。公式如下：<br><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;P=10^-[(n-33)/10]</p>
</li>
<li><p>举个栗子：比如“?”在ASCII码表上对应的编号是63，那么n就是63，减去33以后就是30，也就是我们说的Q30了，所以<code>Q = n - 33</code>，P算出来就是0.001，这个就是错误率，反过来，准确率就是99.9%，Q30就是准确率99.9%，同理Q20就是准确率99%。<br></p>
</li>
<li><p>ok，介绍完格式，介绍两款质控的软件，fastqc和fastp<br></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fastqc：</span><br><span class="line">$ wget http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.7.zip</span><br><span class="line">$ unzip fastqc_v0.11.7.zip</span><br><span class="line">$ cd FastQC/</span><br><span class="line">$ chmod 755 fastqc</span><br><span class="line">fastp：</span><br><span class="line">$ wget http://opengene.org/fastp/fastp</span><br><span class="line">$ chmod 755 fastp</span><br></pre></td></tr></table></figure>

<ul>
<li>以上是我的安装方式，fastqc是一个很常用的软件，我想只要不是小白都用过。对于ubuntu用户请用我提供的方式进行安装，用<code>apt-get install fastqc</code>可能在使用的时候出现如下报错<br></li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/fastqc%E9%94%99%E8%AF%AF.jpg" alt="fastqc错误"></p>
<ul>
<li>至于fastp，是用来清洗质量不好的reads的，其实类似的软件很多，包括trimmomatic等，之所以选择这个是因为用过那么多软件后，发现fastp无论在安装还是使用上都很顺手，仅此而已。<br></li>
<li>好了，现在让我们来使用fastqc对raw data的质量进行分析并查看<br></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] [-c contaminant file] seqfile1 .. seqfileN</span><br><span class="line">#这是fastqc的使用方法，其实很简单，对于不懂的软件，我一般的推荐是，先看官方说明，再逛逛论坛，这里不展开说这个软件怎么使用了，下面是我的使用代码</span><br><span class="line">$ fastqc -o your/path/to/out -t 4 $&#123;datadir&#125;/*.fq.gz</span><br><span class="line">#是不是超级简单，-o是报告输出的目录，这个目录必须是存在的，-t是线程数</span><br></pre></td></tr></table></figure>

<ul>
<li>结果如下，要放在早几年，估计是很难见到这么干净的原始数据了，为此我还专门请教了一些老师，这么干净的数据的可信程度。得益于illumina公司对仪器的升级改善，数据的质量也是越来越好了。<br></li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/fastqc.png" alt="fastqc.png"></p>
<ul>
<li><p>但是即便如此，我们还是要对raw data进行清洗的，数据的质量直接决定了后面分析的准确性，是一切分析的前提，我们一直都在说QC，QC也是基础，但是它的重要性不容忽视。下面是我要查看的质控的内容：<br></p>
<p>​    • read各个位置的碱基质量值分布<br></p>
<p>​    • 碱基的总体质量值分布<br></p>
<p>​    • read各个位置上碱基分布比例，目的是为了分析碱基的分离程度<br><br>​    • GC含量分布<br></p>
<p>​    • read各位置的N含量<br><br>​    • read是否还包含测序的接头序列<br></p>
</li>
<li><p>下面是我的对于clean data的指标：<br></p>
<p>​    1.将含有接头的reads对去除，或者cut接头<br></p>
<p>​    2.测序错误率分布检查，一般情况下，每个碱基位置的测序错误率都应该低于1%<br></p>
<p>​    3.GC含量，理论上A=T，C=G，前几个碱基可能会有波动，GC含量整体在41.5%左右<br><br>​    4.平均质量值分布：Q30平均比例≥80%，平均错误率≤0.1%<br></p>
</li>
<li><p>为了达到这样的目标，我的筛选是条件是：<br></p>
<p>​    去除含接头（adapter）的一对reads；可以酌情考虑去除接头保留reads<br></p>
<p>​    当某一端read中的N含量超过该条read长度比例10%，去除该对reads<br><br>​    当某一端read中低质量（Q≤20）碱基数超过该read长度比例的50%时，去除该对reads<br></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ fastp -i 1.fq.gz -I 2.fq.gz \</span><br><span class="line">	--adapter_sequence $&#123;Adapter_R1&#125; \</span><br><span class="line">	--adapter_sequence_r2 $&#123;Adapter_R2&#125; \#不同的试剂盒、仪器，会有不同的接头，这个可以咨询公司，也可以选择去掉这两个参数，影响不大</span><br><span class="line">	-o your/path/of/data/cleaned.1.fq.gz \</span><br><span class="line">	-O your/path/of/data/cleaned.2.fq.gz \#输出的clean data的位置和名称</span><br><span class="line">	-c -q 20 -u 50 -n 15 -5 20 -3 20 -w 16 \</span><br><span class="line">	-h your/path/of/report/clean.html -j your/path/of/report/clean.json #这俩参数分别是不同格式报告的输出位置和文件名</span><br></pre></td></tr></table></figure>

<ul>
<li><p>别的不多说，解释一下我用到的几个参数:<br></p>
<p>​    -c：对overlap区域进行纠错，适用于PE<br></p>
<p>​    -q：设置低质量的标准，默认是15，多数公司这里设为5<br><br>​    -u：低质量碱基所占比例，默认40代表40%，只要有一条read不满足条件就成对丢掉<br><br>​    -n：过滤N碱基过多的reads，15代表个数，因为一般PE150的reads长度是150<br><br>​    -w：线程数，这里要注意！范围是1-16，建议是8，亲测，8和16差不多<br><br>​    -5 -3：根据质量值来截取reads，分别对应5‘端和3’端，得到reads长度可能不等<br></p>
<p>具体请参考官网说明<br></p>
</li>
<li><p>这个时候再看clean data结果，就无需fastqc了，因为fastp也会生成一份报告。<br></p>
</li>
</ul>
<p><img src="/2019/06/18/WGS分析笔记（1）- 原始数据以及质控/fastp.png" alt="fastp报告部分截图"></p>
<ul>
<li>看到结果，其实可以发现，数据还是保留了大部分的，所以完全不用担心cut太狠，导致数据不够。我的原则是，在数据量面前，更应该保证的是数据的准确性，即使会有一点损失，也是值得的，毕竟research更注重的也是准确性，相对于降低假阴性，我更倾向于提高真阳性。<br></li>
<li>那么得到clean data以后就可以进行下一步mapping了，mapping内容下次再与大家分享。<br></li>
<li>水平有限，要是存在什么错误请评论指出，可发送邮箱至<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>！请大家多多批评指正，相互交流，共同成长，谢谢！！！<br></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/17/WGS分析笔记（0）- 我的数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/17/WGS分析笔记（0）- 我的数据/" class="post-title-link" itemprop="url">WGS分析笔记（0）- 我的数据</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-17 22:15:01" itemprop="dateCreated datePublished" datetime="2019-06-17T22:15:01+08:00">2019-06-17</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-18 00:24:11" itemprop="dateModified" datetime="2019-06-18T00:24:11+08:00">2019-06-18</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/我的WGS/" itemprop="url" rel="index"><span itemprop="name">我的WGS</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>我研究的课题主要是通过二代重测序获得基因组数据进而进行疾病分析<br></li>
</ul>
<hr>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul>
<li>二代测序技术（next generation sequencing，NGS），又称为高通量测序技术（high-throughput sequencing，HTS）或深度测序（deep sequencing），通过一次对几十万到几百万条核酸分子进行序列测定，进而对一个物种的转录组和基因组进行细致全貌的分析<br></li>
<li>一般我们对人类基因组的研究策略主要是三个：<br><ul>
<li>全基因组重测序（whole genome re-sequencing，WGS）<br></li>
<li>全外显子组重测序（whole exome re-sequencing，WES）<br></li>
<li>目标区域测序（target region re-sequencing，TR）<br></li>
</ul>
</li>
<li>对于这三个策略如何应用，这完全看课题需要，没有人说过这三个策略必须分开进行，实际上目前很多课题组在进行研究的时候，都会先分析WES和panel的数据，再考虑进行WGS的测序分析，也有些课题组通过panel筛选病例，再进行WES或WGS的分析。以上只是两个简单的思路，适用于不同的课题需求。那到底怎么去选取研究策略，还是根据课题的需求，这充分说明了，课题设计的重要性，从我踩过的坑来看，一个好的课题设计，能让你后续的分析少碰很多壁，而且我觉得课题是循序渐进的，具体怎么去做要根据预实验好好的验证<br></li>
<li>WGS和WES怎么选择呢，也是看研究疾病的情况，比较而言，WES的成本会低，而目前报道来看80%的疾病都是由于exon区域的突变贡献的，WGS的成本相对较高，深度也不及WES，类似嵌合体什么的，靠WGS是检测不出来的，但是WGS的覆盖广，noncoding区域一直是有待研究的区域，WGS也有利于SV的检测，目前大多数类似文章的研究还是WES为主，但是主流的声响一直在推广WGS<br></li>
<li>而我的课题就是属于没有被好好设计的那种，那么我的研究对象主要是（全是）WGS的数据了，既然这已经改变不了了，那就好好分析，以找出差异基因，争取早日脱离苦海<br></li>
<li>那么之后我要分析的内容其实是以WGS的数据为对象，当然，这并没有太大影响，因为很多分析是大同小异的<br></li>
<li>这里贴一张某测序公司培训时给的WGS数据分析流程，我的样本测序就是交给这家公司来完成的，这张照片比较早，大概是2018年4月时候的培训，不知道这家公司现在还是不是这么分析的，但这并不重要，目前大体的分析流程大同小异，一般发表的文章也会提供分析方法，也是值得大家借鉴的<br></li>
</ul>
<p><img src="/2019/06/17/WGS分析笔记（0）- 我的数据/%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B.png" alt="分析流程"></p>
<ul>
<li>而我后面的分析方法和流程与这里也是有差别的，但我为什么没有贴我自己的流程图呢，主要是因为我的流程细节部分还在不断的修改过程中，我后面的文章会按照我的流程进行一步步的介绍，也会抛出我遇到的问题，希望能得到大家的指点，大家共同交流，批评指正！！！</li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tongshiyuan.github.io/2019/06/17/我搭了一个自己的主页/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TongShiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Taro">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/17/我搭了一个自己的主页/" class="post-title-link" itemprop="url">我搭了一个自己的主页</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-17 21:39:58 / 修改时间：22:09:37" itemprop="dateCreated datePublished" datetime="2019-06-17T21:39:58+08:00">2019-06-17</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>2019年6月17日，天气还是挺热的，我在废了几小时搭建完这个hexo主页以后，决定开始把我的简书文章搬过来了<br></li>
<li>其实我从来没有写这种东西的习惯，在一个朋友的建议下，我开始写，想把我学到的做过的东西记下来，一方面方便以后自己查阅，一方面，如果能帮助到其他人也是好的，毕竟我在学习之初，还是很痛苦的。<br></li>
<li>我本身是比较懒的一个人，所以我一开始选择简书，一个直接往上写东西就行的平台，毕竟对我来说，搭建一个主页好累啊，但是简书实在太过分了，莫名其面锁了我的文章，在我申诉以后还不搭理我，这我就很气了，我的系列文章，你中间给我锁一篇算怎么回事！！！<br></li>
<li>三次申诉无果后，我打算自己建立一个主页，毕竟写技术文章这种是我个人觉得是纯粹找diss的，因为我的技术也就那样，所以装乎我是不会去，而这个主页有个好处是，我没开通评论模块（实在是太麻烦了），这样大家也diss不了我了，但是如果我的文章出现错误，大家完全可以邮件联系我(<a href="mailto:shiyuant@outlook.com" target="_blank" rel="noopener">shiyuant@outlook.com</a>)，我会第一时间答复并且修改<br></li>
<li>希望能和大家多多交流，共同学习进步<br></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div>
  
</div>
    <div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/logo.jpg" alt="TongShiyuan">
            
              <p class="site-author-name" itemprop="name">TongShiyuan</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/tongshiyuan" title="GitHub &rarr; https://github.com/tongshiyuan" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://www.jianshu.com/u/4450f2e08883" title="简书 &rarr; https://www.jianshu.com/u/4450f2e08883" rel="noopener" target="_blank"><i class="fa fa-fw fa-heartbeat"></i>简书</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:shiyuant@outlook.com" title="E-Mail &rarr; mailto:shiyuant@outlook.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TongShiyuan</span>
<!--
  
-->
  
</div>

<!--

  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.1.2</div>



-->

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共17.5k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.2"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  



  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
